{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d78e6e3",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf7a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748a4bd6",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data set and separate columns at ;\n",
    "train = pd.read_csv(\"train.csv\", delimiter = ';')\n",
    "test = pd.read_csv(\"test.csv\", delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af399e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the two dataframes vertically (along rows)\n",
    "Banking_data = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64e2177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get cloumns names\n",
    "Banking_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d1e236",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check for null values\n",
    "Banking_data.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf3ffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the merged dataframe to a new CSV file\n",
    "Banking_data.to_csv(\"Banking_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a61382",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Banking_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c57d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8167c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns with too many unkown values\n",
    "df.drop(columns = ['contact', 'poutcome'], axis = 'columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39deb139",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unwanted columns\n",
    "df.drop(columns = ['marital', 'education','default', 'day', 'campaign'], axis = 'columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4f8d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4ecf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change prediction column name\n",
    "df.rename(columns = {'y':'FDcreated'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e2272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename unclear column names\n",
    "df.rename(columns = {'housing' : 'housingLoan', 'loan': 'personalLoan'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a02be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13418e2",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d31bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change yes = 1 no = 0\n",
    "df['housingLoan'] = df['housingLoan'].map({'yes': 1, 'no':0})\n",
    "df['personalLoan'] = df['personalLoan'].map({'yes': 1, 'no':0})\n",
    "df['FDcreated'] = df['FDcreated'].map({'yes': 1, 'no':0})\n",
    "\n",
    "#Give values for each job and each month\n",
    "df['job'] = df['job'].map({'admin': 1, 'unknown':2 ,'unemployed':3, 'management':4, 'housemaid':5, 'entrepreneur':6, 'student':7, 'blue-collar':8, 'self-employed':9, 'retired':10, 'technician':11, 'services':12})\n",
    "df['month'] = df['month'].map({'jan': 1, 'feb':2 ,'mar':3, 'apr':4, 'may':5, 'jun':6, 'jul':7, 'aug':8, 'sep':9, 'oct':10, 'nov':11, 'dec':12})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f9c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop NAN values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe365607",
   "metadata": {},
   "source": [
    "# Data Visualizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436bd45f",
   "metadata": {},
   "source": [
    "(1)Plot of the Created FD Account or not - Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9d74a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the occurrences of 1s and 0s in the 'FDcreated' column\n",
    "fd_counts = df['FDcreated'].value_counts()\n",
    "\n",
    "# Create a bar plot\n",
    "plt.bar(fd_counts.index, fd_counts.values)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('FD Created (1) vs Not Created (0)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of FD Creation')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85ae7ef",
   "metadata": {},
   "source": [
    "(2)Compare the ages of customers who took fixed deposit and who didnâ€™t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff52045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796094e9",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191e1ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide dataset into independent and dependent variables\n",
    "X = df.iloc[:,:-1].values \n",
    "y = df.iloc[:,-1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af6954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5a0364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2550054c",
   "metadata": {},
   "source": [
    "Decision Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e84c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "# Create the Decision Tree Classifier model\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "dt_pred = dt.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, dt_pred)\n",
    "print(\"Accuracy of Decision Tree classifier :\", accuracy)\n",
    "\n",
    "# Create a pickle file for the model\n",
    "dt_pickle = open('dt_model.pkl', 'wb') \n",
    "pickle.dump(dt, dt_pickle)\n",
    "dt_pickle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ebaf8f",
   "metadata": {},
   "source": [
    "KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041be8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "# Create the KNeighborsClassifier model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "knn_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "knn_accuracy = accuracy_score(y_test, knn_pred)\n",
    "print(\"Accuracy of KNeighbors Classifier:\", knn_accuracy)\n",
    "\n",
    "# Create a pickle file for the model\n",
    "knn_pickle = open('knn_model.pkl', 'wb') \n",
    "pickle.dump(knn, knn_pickle)\n",
    "knn_pickle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2105e6a8",
   "metadata": {},
   "source": [
    "Linear regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db14376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "\n",
    "# Create the LinearRegression model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "reg_pred = reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model (using Mean Squared Error as it's a regression problem)\n",
    "mse = mean_squared_error(y_test, reg_pred)\n",
    "print(\"Mean Squared Error (MSE) of Linear Regression Model:\", mse)\n",
    "\n",
    "lr_acc = 1-mse\n",
    "print(\"Accuracy of Linear regression Model classifier :\", lr_acc)\n",
    "\n",
    "# Create a pickle file for the model\n",
    "linear_regression_pickle = open('linear_regression_model.pkl', 'wb') \n",
    "pickle.dump(reg, linear_regression_pickle)\n",
    "linear_regression_pickle.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872263e1",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce6bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "# Create the SVC model\n",
    "svc = SVC()\n",
    "\n",
    "# Train the model\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "svc_pred = svc.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "svc_accuracy = accuracy_score(y_test, svc_pred)\n",
    "print(\"Accuracy of Support Vector Machine:\", svc_accuracy)\n",
    "\n",
    "svc_error = 1 - svc_accuracy\n",
    "print(\"Error of Support Vector Machine:\", svc_error)\n",
    "\n",
    "# Create a pickle file for the model\n",
    "svc_pickle = open('support_vector_machine.pkl', 'wb') \n",
    "pickle.dump(svc, svc_pickle)\n",
    "svc_pickle.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
